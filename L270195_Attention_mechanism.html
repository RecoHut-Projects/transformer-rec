
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Attention mechanism &#8212; transformer-rec</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Transformers" href="L879284_Transformers.html" />
    <link rel="prev" title="Language modeling approaches" href="L413721_Language_modeling_approaches.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">transformer-rec</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="US780867_Transformer_based_Recommenders.html">
   Transformer-based Recommenders
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Concepts
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="L413721_Language_modeling_approaches.html">
   Language modeling approaches
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Attention mechanism
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L879284_Transformers.html">
   Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L137141_Stochastic_shared_embeddings.html">
   Stochastic shared embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L201302_GeLU_activation.html">
   GeLU activation
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Baselines
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="C889944_GRU4Rec.html">
   GRU4Rec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="C505509_Caser.html">
   Caser
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="C001344_NARM.html">
   NARM
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="C065971_SASRec.html">
   SASRec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="C759066_BERT4Rec.html">
   BERT4Rec
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="C220331_BST.html">
   BST
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="C655229_SSE_PT.html">
   SSE-PT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="C776172_DMT.html">
   DMT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="C879945_MATN.html">
   MATN
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/L270195_Attention_mechanism.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sparsh-ai/transformer-rec/main?urlpath=lab/tree/docs/L270195_Attention_mechanism.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/sparsh-ai/transformer-rec/blob/main/docs/L270195_Attention_mechanism.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#queries-keys-and-values">
   Queries, Keys, and Values
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#attention-pooling">
   Attention Pooling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#average-pooling">
     Average Pooling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nonparametric-attention-pooling">
     Nonparametric Attention Pooling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parametric-attention-pooling">
     <strong>
      Parametric Attention Pooling
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#attention-scoring-functions">
   Attention Scoring Functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#additive-attention">
     Additive Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scaled-dot-product-attention">
     Scaled Dot-Product Attention
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-of-popular-attention-mechanisms">
     Summary of Popular Attention Mechanisms
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bahdanau-attention">
   Bahdanau Attention
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multi-head-attention">
   Multi-Head Attention
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#self-attention">
   Self-Attention
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transformer">
   Transformer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="attention-mechanism">
<h1>Attention mechanism<a class="headerlink" href="#attention-mechanism" title="Permalink to this headline">¶</a></h1>
<p>Attention is, to some extent, motivated by how we pay visual attention to different regions of an image or correlate words in one sentence. Take the picture of a Shiba Inu as an example.</p>
<p><center><img src='_images/L270195_1.png'></center></p>
<p>A Shiba Inu in a men’s outfit. The credit of the original photo goes to Instagram &#64;mensweardog.</p>
<p>Human visual attention allows us to focus on a certain region with “high resolution” (i.e. look at the pointy ear in the yellow box) while perceiving the surrounding image in “low resolution” (i.e. now how about the snowy background and the outfit?), and then adjust the focal point or do the inference accordingly. Given a small patch of an image, pixels in the rest provide clues what should be displayed there. We expect to see a pointy ear in the yellow box because we have seen a dog’s nose, another pointy ear on the right, and Shiba’s mystery eyes (stuff in the red boxes). However, the sweater and blanket at the bottom would not be as helpful as those doggy features.</p>
<p>Similarly, we can explain the relationship between words in one sentence or close context. When we see “eating”, we expect to encounter a food word very soon. The color term describes the food, but probably not so much with “eating” directly.</p>
<p><center><img src='_images/L270195_2.png'></center></p>
<p>One word “attends” to other words in the same sentence differently.</p>
<p>In a nutshell, attention in deep learning can be broadly interpreted as a vector of importance weights: in order to predict or infer one element, such as a pixel in an image or a word in a sentence, we estimate using the attention vector how strongly it is correlated with (or “attends to” as you may have read in many papers) other elements and take the sum of their values weighted by the attention vector as the approximation of the target.</p>
<p>The optic nerve of a primate’s visual system receives massive sensory input, far exceeding what the brain can fully process. Fortunately, not all stimuli are created equal. Focalization and concentration of consciousness have enabled primates to direct attention to objects of interest, such as preys and predators, in the complex visual environment. The ability of paying attention to only a small fraction of the information has evolutionary significance, allowing human beings to live and succeed.</p>
<p>Scientists have been studying attention in the cognitive neuroscience field since the 19th century. Notably, the Nadaraya-Waston kernel regression in 1964 is a simple demonstration of machine learning with attention mechanisms.</p>
<p>Attention is a scarce resource: at the moment you are reading this text and ignoring the rest. Thus, similar to money, your attention is being paid with an opportunity cost. Attention is the keystone in the arch of life and holds the key to any work’s exceptionalism.</p>
<p>Since economics studies the allocation of scarce resources, we are in the era of the attention economy, where human attention is treated as a limited, valuable, and scarce commodity that can be exchanged. Numerous business models have been developed to capitalize on it. On music or video streaming services, we either pay attention to their ads or pay money to hide them. For growth in the world of online games, we either pay attention to participate in battles, which attract new gamers, or pay money to instantly become powerful. Nothing comes for free.</p>
<p>All in all, information in our environment is not scarce, attention is. When inspecting a visual scene, our optic nerve receives information at the order of <span class="math notranslate nohighlight">\(10^8\)</span> bits per second, far exceeding what our brain can fully process. Fortunately, our ancestors had learned from experience (also known as data) that not all sensory inputs are created equal. Throughout human history, the capability of directing attention to only a fraction of information of interest has enabled our brain to allocate resources more smartly to survive, to grow, and to socialize, such as detecting predators, preys, and mates.</p>
<p>To explain how our attention is deployed in the visual world, a two-component framework has emerged and been pervasive. This idea dates back to William James in the 1890s, who is considered the “father of American psychology” <strong><a class="reference external" href="https://d2l.ai/chapter_references/zreferences.html#james-2007">[James, 2007]</a></strong>. In this framework, subjects selectively direct the spotlight of attention using both the <em>nonvolitional cue</em> and <em>volitional cue</em>.</p>
<p>The nonvolitional cue is based on the saliency and conspicuity of objects in the environment. Imagine there are five objects in front of you: a newspaper, a research paper, a cup of coffee, a notebook, and a book. While all the paper products are printed in black and white, the coffee cup is red. In other words, this coffee is intrinsically salient and conspicuous in this visual environment, automatically and involuntarily drawing attention. So you bring the fovea (the center of the macula where visual acuity is highest) onto the coffee.</p>
<p><center><img src='_images/L270195_3.png'></center></p>
<p>After drinking coffee, you become caffeinated and want to read a book. So you turn your head, refocus your eyes, and look at the book. Different from the above case where the coffee biases you towards selecting based on saliency, in this task-dependent case you select the book under cognitive and volitional control. Using the volitional cue based on variable selection criteria, this form of attention is more deliberate. It is also more powerful with the subject’s voluntary effort.</p>
<p><center><img src='_images/L270195_4.png'></center></p>
<div class="section" id="queries-keys-and-values">
<h2>Queries, Keys, and Values<a class="headerlink" href="#queries-keys-and-values" title="Permalink to this headline">¶</a></h2>
<p>Inspired by the nonvolitional and volitional attention cues that explain the attentional deployment, in the following we will describe a framework for designing attention mechanisms by incorporating these two attention cues.</p>
<p>To begin with, consider the simpler case where only nonvolitional cues are available. To bias selection over sensory inputs, we can simply use a parameterized fully-connected layer or even non-parameterized max or average pooling.</p>
<p>Therefore, what sets attention mechanisms apart from those fully-connected layers or pooling layers is the inclusion of the volitional cues. In the context of attention mechanisms, we refer to volitional cues as <em>queries</em>. Given any query, attention mechanisms bias selection over sensory inputs (e.g., intermediate feature representations) via <em>attention pooling</em>. These sensory inputs are called <em>values</em> in the context of attention mechanisms. More generally, every value is paired with a <em>key</em>, which can be thought of the nonvolitional cue of that sensory input. We can design attention pooling so that the given query (volitional cue) can interact with keys (nonvolitional cues), which guides bias selection over values (sensory inputs).</p>
<p><center><img src='_images/L270195_5.png'></center></p>
<p>Attention mechanisms bias selection over values (sensory inputs) via attention pooling, which incorporates queries (volitional cues) and keys (nonvolitional cues).</p>
<p>To recapitulate, the interactions between queries (volitional cues) and keys (nonvolitional cues) result in attention pooling. The attention pooling selectively aggregates values (sensory inputs) to produce the output.</p>
<p>Note that there are many alternatives for the design of attention mechanisms. For instance, we can design a non-differentiable attention model that can be trained using reinforcement learning methods [Mnih et al., 2014]. Given the dominance of the framework in the above figure, models under this framework will be the center of our attention next.</p>
</div>
<div class="section" id="attention-pooling">
<h2>Attention Pooling<a class="headerlink" href="#attention-pooling" title="Permalink to this headline">¶</a></h2>
<p>The Nadaraya-Watson kernel regression model proposed in 1964 is a simple yet complete example for demonstrating machine learning with attention mechanisms.</p>
<p>To keep things simple, let us consider the following regression problem: given a dataset of input-output pairs <span class="math notranslate nohighlight">\(\{(x_1, y_1), \ldots, (x_n, y_n)\}\)</span>, how to learn <span class="math notranslate nohighlight">\(f\)</span> to predict the output <span class="math notranslate nohighlight">\(\hat{y} = f(x)\)</span> for any new input <span class="math notranslate nohighlight">\(x\)</span>? Let’s take a non-linear function: <span class="math notranslate nohighlight">\(y_i = 2\sin(x_i) + x_i^{0.8} + \epsilon\)</span>.</p>
<div class="section" id="average-pooling">
<h3>Average Pooling<a class="headerlink" href="#average-pooling" title="Permalink to this headline">¶</a></h3>
<p>We begin with perhaps the world’s “dumbest” estimator for this regression problem: using average pooling to average over all the training outputs:</p>
<div class="math notranslate nohighlight">
\[f(x) = \frac{1}{n}\sum_{i=1}^n y_i\]</div>
</div>
<div class="section" id="nonparametric-attention-pooling">
<h3>Nonparametric Attention Pooling<a class="headerlink" href="#nonparametric-attention-pooling" title="Permalink to this headline">¶</a></h3>
<p>Obviously, average pooling omits the inputs <span class="math notranslate nohighlight">\(x_i\)</span> . A better idea was proposed by Nadaraya [Nadaraya, 1964] and Watson [Watson, 1964] to weigh the outputs <span class="math notranslate nohighlight">\(y_i\)</span> according to their input locations:</p>
<div class="math notranslate nohighlight">
\[f(x) = \sum_{i=1}^n \frac{K(x - x_i)}{\sum_{j=1}^n K(x - x_j)} y_i\]</div>
<p>A key <span class="math notranslate nohighlight">\(x_i\)</span> that is closer to the given query <span class="math notranslate nohighlight">\(x\)</span> will get more attention via a larger attention weight assigned to the key’s corresponding value <span class="math notranslate nohighlight">\(y_i\)</span>. To gain intuitions of attention pooling, just consider a Gaussian kernel defined as:</p>
<div class="math notranslate nohighlight">
\[K(u) = \frac{1}{\sqrt{2\pi}} \exp(-\frac{u^2}{2})\]</div>
<p>Plugging the Gaussian kernel into the above equation gives:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}\begin{aligned} f(x) &amp;= \sum_{i=1}^n \frac{\exp\left(-\frac{1}{2}(x - x_i)^2\right)}{\sum_{j=1}^n \exp\left(-\frac{1}{2}(x - x_j)^2\right)} y_i \\&amp;= \sum_{i=1}^n \mathrm{softmax}\left(-\frac{1}{2}(x - x_i)^2\right) y_i\end{aligned}\end{split}\end{split}\]</div>
<p>Notably, Nadaraya-Watson kernel regression is a nonparametric model; thus the above equation is an example of nonparametric attention pooling.</p>
</div>
<div class="section" id="parametric-attention-pooling">
<h3><strong>Parametric Attention Pooling</strong><a class="headerlink" href="#parametric-attention-pooling" title="Permalink to this headline">¶</a></h3>
<p>Nonparametric Nadaraya-Watson kernel regression enjoys the <em>consistency</em> benefit: given enough data this model converges to the optimal solution. Nonetheless, we can easily integrate learnable parameters into attention pooling.</p>
<p>As an example, slightly different from the above equation, in the following the distance between the query <span class="math notranslate nohighlight">\(x\)</span> and the key <span class="math notranslate nohighlight">\(x_i\)</span> is multiplied by a learnable parameter <span class="math notranslate nohighlight">\(w\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}\begin{aligned}f(x) &amp;= \sum_{i=1}^n \frac{\exp\left(-\frac{1}{2}((x - x_i)w)^2\right)}{\sum_{j=1}^n \exp\left(-\frac{1}{2}((x - x_j)w)^2\right)} y_i \\&amp;= \sum_{i=1}^n \mathrm{softmax}\left(-\frac{1}{2}((x - x_i)w)^2\right) y_i.\end{aligned}\end{split}\end{split}\]</div>
</div>
</div>
<div class="section" id="attention-scoring-functions">
<h2>Attention Scoring Functions<a class="headerlink" href="#attention-scoring-functions" title="Permalink to this headline">¶</a></h2>
<p><center><img src='_images/L270195_6.png'></center></p>
<p>Mathematically, suppose that we have a query <span class="math notranslate nohighlight">\(q∈\mathbb{R}^q\)</span> and <span class="math notranslate nohighlight">\(m\)</span> key-value pairs <span class="math notranslate nohighlight">\((k_1,v_1),…,(k_m,v_m)\)</span>, where any <span class="math notranslate nohighlight">\(k_i∈\mathbb{R}^k\)</span> and any <span class="math notranslate nohighlight">\(v_i∈\mathbb{R}^v\)</span>. The attention pooling <span class="math notranslate nohighlight">\(f\)</span> is instantiated as a weighted sum of the values:</p>
<div class="math notranslate nohighlight">
\[f(\mathbf{q}, (\mathbf{k}_1, \mathbf{v}_1), \ldots, (\mathbf{k}_m, \mathbf{v}_m)) = \sum_{i=1}^m \alpha(\mathbf{q}, \mathbf{k}_i) \mathbf{v}_i \in \mathbb{R}^v\]</div>
<p>where the attention weight (scalar) for the query q and key <span class="math notranslate nohighlight">\(k_i\)</span> is computed by the softmax operation of an attention scoring function a that maps two vectors to a scalar:</p>
<div class="math notranslate nohighlight">
\[\alpha(\mathbf{q}, \mathbf{k}_i) = \mathrm{softmax}(a(\mathbf{q}, \mathbf{k}_i)) = \frac{\exp(a(\mathbf{q}, \mathbf{k}_i))}{\sum_{j=1}^m \exp(a(\mathbf{q}, \mathbf{k}_j))} \in \mathbb{R}\]</div>
<p>As we can see, different choices of the attention scoring function a lead to different behaviors of attention pooling.</p>
<div class="section" id="additive-attention">
<h3>Additive Attention<a class="headerlink" href="#additive-attention" title="Permalink to this headline">¶</a></h3>
<p>In general, when queries and keys are vectors of different lengths, we can use additive attention as the scoring function. Given a query <span class="math notranslate nohighlight">\(q∈\mathbb{R}^q\)</span> and a key <span class="math notranslate nohighlight">\(k∈\mathbb{R}^k\)</span>, the additive attention scoring function:</p>
<div class="math notranslate nohighlight">
\[a(\mathbf q, \mathbf k) = \mathbf w_v^\top \text{tanh}(\mathbf W_q\mathbf q + \mathbf W_k \mathbf k) \in \mathbb{R}\]</div>
<p>where learnable parameters <span class="math notranslate nohighlight">\(W_q∈\mathbb{R}^{h×q}\)</span>, <span class="math notranslate nohighlight">\(W_k∈\mathbb{R}^{h×k}\)</span>, and <span class="math notranslate nohighlight">\(w_v∈\mathbb{R}^{h}\)</span>.</p>
</div>
<div class="section" id="scaled-dot-product-attention">
<h3>Scaled Dot-Product Attention<a class="headerlink" href="#scaled-dot-product-attention" title="Permalink to this headline">¶</a></h3>
<p>A more computationally efficient design for the scoring function can be simply dot product. However, the dot product operation requires that both the query and the key have the same vector length, say <span class="math notranslate nohighlight">\(d\)</span>. Assume that all the elements of the query and the key are independent random variables with zero mean and unit variance. The dot product of both vectors has zero mean and a variance of <span class="math notranslate nohighlight">\(d\)</span>. To ensure that the variance of the dot product still remains one regardless of vector length, the <em>scaled dot-product attention</em> scoring function <span class="math notranslate nohighlight">\(a(\mathbf q, \mathbf k) = \mathbf{q}^\top \mathbf{k} /\sqrt{d}\)</span> divides the dot product by <span class="math notranslate nohighlight">\(\sqrt{d}\)</span>.</p>
<p>In practice, we often think in minibatches for efficiency, such as computing attention for <span class="math notranslate nohighlight">\(n\)</span> queries and <span class="math notranslate nohighlight">\(m\)</span> key-value pairs, where queries and keys are of length <span class="math notranslate nohighlight">\(d\)</span> and values are of length <span class="math notranslate nohighlight">\(v\)</span>. The scaled dot-product attention of queries <span class="math notranslate nohighlight">\(Q∈\mathbb{R}^{n×d}\)</span>, keys <span class="math notranslate nohighlight">\(K∈\mathbb{R}^{m×d}\)</span>, and values <span class="math notranslate nohighlight">\(V∈\mathbb{R}^{m×v}\)</span> is:</p>
<div class="math notranslate nohighlight">
\[\mathrm{softmax}\left(\frac{\mathbf Q \mathbf K^\top }{\sqrt{d}}\right) \mathbf V \in \mathbb{R}^{n\times v}\]</div>
</div>
<div class="section" id="summary-of-popular-attention-mechanisms">
<h3>Summary of Popular Attention Mechanisms<a class="headerlink" href="#summary-of-popular-attention-mechanisms" title="Permalink to this headline">¶</a></h3>
<p>Below is a summary table of several popular attention mechanisms and corresponding alignment score functions:</p>
<p><center><img src='_images/L270195_7.png'></center></p>
<p>Here are a summary of broader categories of attention mechanisms:</p>
<p><center><img src='_images/L270195_8.png'></center></p>
</div>
</div>
<div class="section" id="bahdanau-attention">
<h2>Bahdanau Attention<a class="headerlink" href="#bahdanau-attention" title="Permalink to this headline">¶</a></h2>
<p>Inspired by the idea of learning to align, Bahdanau et al. proposed a differentiable attention model without the severe unidirectional alignment limitation [<a class="reference external" href="https://d2l.ai/chapter_references/zreferences.html#bahdanau-cho-bengio-2014">Bahdanau et al., 2014</a>]. When predicting a token, if not all the input tokens are relevant, the model aligns (or attends) only to parts of the input sequence that are relevant to the current prediction. This is achieved by treating the context variable as an output of attention pooling.</p>
<p><center><img src='_images/L270195_9.png'></center></p>
<p>Layers in an RNN encoder-decoder model with Bahdanau attention.</p>
</div>
<div class="section" id="multi-head-attention">
<h2>Multi-Head Attention<a class="headerlink" href="#multi-head-attention" title="Permalink to this headline">¶</a></h2>
<p>In practice, given the same set of queries, keys, and values we may want our model to combine knowledge from different behaviors of the same attention mechanism, such as capturing dependencies of various ranges (e.g., shorter-range vs. longer-range) within a sequence. Thus, it may be beneficial to allow our attention mechanism to jointly use different representation subspaces of queries, keys, and values.</p>
<p>To this end, instead of performing a single attention pooling, queries, keys, and values can be transformed with <span class="math notranslate nohighlight">\(h\)</span> independently learned linear projections. Then these <span class="math notranslate nohighlight">\(h\)</span> projected queries, keys, and values are fed into attention pooling in parallel. In the end, <span class="math notranslate nohighlight">\(h\)</span> attention pooling outputs are concatenated and transformed with another learned linear projection to produce the final output. This design is called <em>multi-head attention</em>, where each of the <span class="math notranslate nohighlight">\(h\)</span> attention pooling outputs is a <em>head</em> <strong><a class="reference external" href="https://d2l.ai/chapter_references/zreferences.html#vaswani-shazeer-parmar-ea-2017">[Vaswani et al., 2017]</a></strong>. Using fully-connected layers to perform learnable linear transformations</p>
<p><center><img src='_images/L270195_10.png'></center></p>
<p>Multi-head attention, where multiple heads are concatenated then linearly transformed.</p>
<p>More formally, Given a query <span class="math notranslate nohighlight">\(q∈\mathbb{R}^{d_q}\)</span> , a key <span class="math notranslate nohighlight">\(k∈\mathbb{R}^{d_k}\)</span>, and a value <span class="math notranslate nohighlight">\(v∈\mathbb{R}^{d_v}\)</span>, each attention head <span class="math notranslate nohighlight">\(h_i ( i=1,…,h )\)</span> is computed as:</p>
<div class="math notranslate nohighlight">
\[\mathbf{h}_i = f(\mathbf W_i^{(q)}\mathbf q, \mathbf W_i^{(k)}\mathbf k,\mathbf W_i^{(v)}\mathbf v) \in \mathbb R^{p_v}\]</div>
</div>
<div class="section" id="self-attention">
<h2>Self-Attention<a class="headerlink" href="#self-attention" title="Permalink to this headline">¶</a></h2>
<p>Self-attention is a basic form of a scaled self-attention mechanism. This mechanism uses an input matrix shown as X and produces an attention score between various items in X. We see X as a 3x4 matrix where 3 represents the number of tokens and 4 presents the embedding size. Q is also known as the query, K is known as the key, and V is noted as the value. Three types of matrices shown as theta, phi, and g are multiplied by X before producing Q, K, and V. The multiplied result between query (Q) and key (K) yields an attention score matrix. This can also be seen as a database where we use the query and keys in order to find out how much various items are related in terms of numeric evaluation. Multiplication of the attention score and the V matrix produces the final result of this type of attention mechanism. The main reason for it being called self-attention is because of its unified input X; Q, K, and V are computed from X.</p>
<p><center><img src='_images/L270195_11.png'></center></p>
<p>Imagine that we feed a sequence of tokens into attention pooling so that the same set of tokens act as queries, keys, and values. Specifically, each query attends to all the key-value pairs and generates one attention output. Since the queries, keys, and values come from the same place, this performs self-attention [Lin et al., 2017b][Vaswani et al., 2017], which is also called intra-attention [Cheng et al., 2016][Parikh et al., 2016][Paulus et al., 2017].</p>
<p><center><img src='_images/L270195_12.png'></center></p>
<p>Comparing CNN (padding tokens are omitted), RNN, and self-attention architectures.</p>
<p>Instead of looking for an input-output sequence association/alignment, we are now looking for scores between the elements of the sequence, as depicted below:</p>
<p><center><img src='_images/L270195_13.png'></center></p>
</div>
<div class="section" id="transformer">
<h2>Transformer<a class="headerlink" href="#transformer" title="Permalink to this headline">¶</a></h2>
<p>Different from Bahdanau attention for sequence to sequence learning, the input (source) and output (target) sequence embeddings are added with positional encoding before being fed into the encoder and the decoder that stack modules based on self-attention.</p>
<p><center><img src='_images/L270195_14.png'></center></p>
<p>The transformer architecture.</p>
<p>On a high level, the transformer encoder is a stack of multiple identical layers, where each layer has two sublayers (either is denoted as <span class="math notranslate nohighlight">\(sublayer\)</span>). The first is a multi-head self-attention pooling and the second is a position-wise feed-forward network. Specifically, in the encoder self-attention, queries, keys, and values are all from the the outputs of the previous encoder layer. Inspired by the ResNet design, a residual connection is employed around both sublayers. In the transformer, for any input <span class="math notranslate nohighlight">\(x∈\mathbb{R}^d\)</span> at any position of the sequence, we require that <span class="math notranslate nohighlight">\(sublayer(x)∈\mathbb{R}^d\)</span> so that the residual connection <span class="math notranslate nohighlight">\(x+sublayer(x)∈\mathbb{R}^d\)</span> is feasible. This addition from the residual connection is immediately followed by layer normalization <strong><a class="reference external" href="https://d2l.ai/chapter_references/zreferences.html#ba-kiros-hinton-2016">[Ba et al., 2016]</a></strong>. As a result, the transformer encoder outputs a <span class="math notranslate nohighlight">\(d\)</span>-dimensional vector representation for each position of the input sequence.</p>
<p>The transformer decoder is also a stack of multiple identical layers with residual connections and layer normalizations. Besides the two sublayers described in the encoder, the decoder inserts a third sublayer, known as the encoder-decoder attention, between these two. In the encoder-decoder attention, queries are from the outputs of the previous decoder layer, and the keys and values are from the transformer encoder outputs. In the decoder self-attention, queries, keys, and values are all from the the outputs of the previous decoder layer. However, each position in the decoder is allowed to only attend to all positions in the decoder up to that position. This <em>masked</em> attention preserves the auto-regressive property, ensuring that the prediction only depends on those output tokens that have been generated.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p><a class="reference external" href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html">https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html</a></p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "sparsh-ai/transformer-rec",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="L413721_Language_modeling_approaches.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Language modeling approaches</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="L879284_Transformers.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Transformers</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Sparsh A.<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>